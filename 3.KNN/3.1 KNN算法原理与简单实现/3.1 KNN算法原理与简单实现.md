# 3.1 KNN算法原理与简单实现

> K最近邻(k-Nearest Neighbor，KNN)分类算法，是最简单的机器学习算法之一，涉及高等数学知识近乎为0，是入门机器学习的首选算法。但很多教程只是一笔带过，在这里通过该算法，我们可以学习到在机器学习中所涉及的其他知识点和需要注意的地方。

- 在之前的鸢尾花数据集中，我们只将2种花的150个样本的前2个特征在二维特征空间中表示，如下图

<img src="https://i.loli.net/2018/11/08/5be4502d4c9d3.png" width="68%"/>

- 那么当来了一个新的数据(如下图中绿色的点)，我们如何判断它最可能属于哪种花呢

<img src="https://i.loli.net/2018/11/08/5be450312459c.png" width="70%"/>

### KNN算法原理

- 我们先取一个k值(即KNN中的"K")，在这里我们先根据经验假设取得了最优值k=3。K近邻算法做的事情就是**对于每个新的点，我们计算出距离它最近的前k个点，然后这k个点进行投票**，在这里k=3，如下图所示

<img src="https://i.loli.net/2018/11/08/5be4503118edd.png" width="70%"/>

- 这个例子中，蓝色:红色为2:1

<img src="https://i.loli.net/2018/11/08/5be45031188bd.png" width="70%"/>

- 因此该新的绿色数据点更有可能属于蓝色类别的花

<img src="https://i.loli.net/2018/11/08/5be450316795b.png" width="70%"/>

- 即KNN算法就是通过**各样本之间的相似程度(样本空间中的距离)**作出判断，因此只考虑1个样本是不具有说服力的，通常我们考虑k为多个

### KNN算法的简单实现

---

- 作者：Exrick
- Github地址：https://github.com/Exrick/Machine-Learning
- 版权声明：著作权归作者所有，商业转载请联系作者获得授权，非商业转载请注明出处。
